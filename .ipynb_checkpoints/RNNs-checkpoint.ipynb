{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOEzH19w5qCg"
   },
   "source": [
    "# Machine translation using RNN\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6VSBNYAY5qCj",
    "nbgrader": {
     "grade": false,
     "grade_id": "2bfb8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hy_bmImR5bge",
    "outputId": "1f1079c7-b422-4ce8-afcb-07cdcb9e0245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eVViPow45qCk",
    "nbgrader": {
     "grade": false,
     "grade_id": "b7efae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {} #\n",
    "        self.word2count = {} # words counter\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        # Add words splitting the sentence by space\n",
    "        ### BEGIN SOLUTION\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # Update self.word2index, self.word2count, self.n_words\n",
    "        ### BEGIN SOLUTION\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0CP1P_7uNx",
    "outputId": "cf9513a6-5b7d-497c-c49d-7b25ecf8f799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bye': 4,\n",
       "  'my': 1,\n",
       "  'dear': 1,\n",
       "  'could': 1,\n",
       "  'you': 1,\n",
       "  'please': 1,\n",
       "  'stop': 1,\n",
       "  'the': 1,\n",
       "  'noise': 1},\n",
       " {'bye': 2,\n",
       "  'my': 3,\n",
       "  'dear': 4,\n",
       "  'could': 5,\n",
       "  'you': 6,\n",
       "  'please': 7,\n",
       "  'stop': 8,\n",
       "  'the': 9,\n",
       "  'noise': 10},\n",
       " {0: 'SOS',\n",
       "  1: 'EOS',\n",
       "  2: 'bye',\n",
       "  3: 'my',\n",
       "  4: 'dear',\n",
       "  5: 'could',\n",
       "  6: 'you',\n",
       "  7: 'please',\n",
       "  8: 'stop',\n",
       "  9: 'the',\n",
       "  10: 'noise'},\n",
       " 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lang = Lang(\"eng\")\n",
    "lang.addSentence(\"could you please stop the noise\")\n",
    "lang.word2count, lang.word2index, lang.index2word, lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XEU0ZSU75qCl",
    "nbgrader": {
     "grade": true,
     "grade_id": "2fea4b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_lang = Lang('test')\n",
    "test_lang.addSentence('Hello, World!')\n",
    "assert test_lang.n_words == 4\n",
    "assert test_lang.word2index == {'Hello,': 2, 'World!': 3}\n",
    "assert test_lang.word2count == {'Hello,': 1, 'World!': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wVgmYjqG5qCl",
    "nbgrader": {
     "grade": false,
     "grade_id": "e60806",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A0GQZID05qCm",
    "nbgrader": {
     "grade": false,
     "grade_id": "15a5d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbSjcd6a9LkS",
    "outputId": "ed8c5d68-e5cc-4947-d294-18b76475ebf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-21 07:58:30--  https://download.pytorch.org/tutorial/data.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 18.239.83.126, 18.239.83.16, 18.239.83.32, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|18.239.83.126|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2882130 (2.7M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "\r",
      "data.zip              0%[                    ]       0  --.-KB/s               \r",
      "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-08-21 07:58:30 (85.4 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
      "\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/eng-fra.txt        \n",
      "   creating: data/names/\n",
      "  inflating: data/names/Arabic.txt   \n",
      "  inflating: data/names/Chinese.txt  \n",
      "  inflating: data/names/Czech.txt    \n",
      "  inflating: data/names/Dutch.txt    \n",
      "  inflating: data/names/English.txt  \n",
      "  inflating: data/names/French.txt   \n",
      "  inflating: data/names/German.txt   \n",
      "  inflating: data/names/Greek.txt    \n",
      "  inflating: data/names/Irish.txt    \n",
      "  inflating: data/names/Italian.txt  \n",
      "  inflating: data/names/Japanese.txt  \n",
      "  inflating: data/names/Korean.txt   \n",
      "  inflating: data/names/Polish.txt   \n",
      "  inflating: data/names/Portuguese.txt  \n",
      "  inflating: data/names/Russian.txt  \n",
      "  inflating: data/names/Scottish.txt  \n",
      "  inflating: data/names/Spanish.txt  \n",
      "  inflating: data/names/Vietnamese.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E4-DBhVH5qCm",
    "nbgrader": {
     "grade": false,
     "grade_id": "49e7f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37YmmX7N8_8J",
    "outputId": "0fba1421-aaf4-4d73-d27c-68f074dfd335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"i am a bit scared of everything\"\n",
    "sentence.startswith(eng_prefixes), len(sentence.split(\" \"))\n",
    "pair = [sentence, \"Sono spaventato\"]\n",
    "filterPair(pair)\n",
    "pair = [\"Sono spaventato\", sentence]\n",
    "filterPair(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HA2WHvr8nop",
    "outputId": "fb58942a-32cd-445f-8454-bf219404821a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterPair([\"I'm\", \"I am\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXUdidvV5qCm",
    "nbgrader": {
     "grade": false,
     "grade_id": "072b6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "51e7d902-ef93-421e-9ecc-a70e33eebde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['il embrasse tres bien .', 'he s a great kisser .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# Uncomment if data does not exists\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip\n",
    "# !unzip data.zip > /dev/null\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "EeHW-vaP5qCn",
    "nbgrader": {
     "grade": false,
     "grade_id": "d3c5ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    # split sentence by space and convert words to indices\n",
    "    ### BEGIN SOLUTION\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    ### END SOLUTION\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbvh9cq4-etV",
    "outputId": "0a47dad3-c4be-44a8-dd13-05a9d09fa161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1700, 1097, 532, 2219, 129]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexesFromSentence(output_lang, \"i will try to fix you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYT-SpjR--T4",
    "outputId": "bc41155f-ece3-45b7-c82a-f525de4c10e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2],\n",
      "        [1700],\n",
      "        [1097],\n",
      "        [ 532],\n",
      "        [2219],\n",
      "        [ 129],\n",
      "        [   1]], device='cuda:0')\n",
      "torch.Size([7, 1])\n",
      "torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt = tensorFromSentence(output_lang, \"i will try to fix you\")\n",
    "print (ptt)\n",
    "print (ptt.shape), print (ptt.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "YdYO6Ylt5qCn",
    "nbgrader": {
     "grade": true,
     "grade_id": "19371d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert indexesFromSentence(output_lang, 'master driver') == [975, 977]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "9uyeNfSCITnZ"
   },
   "outputs": [],
   "source": [
    "nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "erTQTo_F5qCn",
    "nbgrader": {
     "grade": false,
     "grade_id": "dbc772",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size) # Special learnable layer which converts tensor of word indices to tensor of hidden size\n",
    "        # Define your RNN here\n",
    "        ### BEGIN SOLUTION\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # HINT 1: input is single sentence of word indexes\n",
    "        # HINT 2: PyTorch RNNs takes [seq_len, batch_size, hidden_size] tensor as input\n",
    "        ### BEGIN SOLUTION\n",
    "        embedded = self.embedding(input).view(-1, 1, self.hidden_size)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        ### END SOLUTION\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "n7mrtOrkSbCq"
   },
   "outputs": [],
   "source": [
    "nn.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "MwfagzO55qCo",
    "nbgrader": {
     "grade": false,
     "grade_id": "cf9459",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        ### END SOLUTION\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        ### BEGIN SOLUTION\n",
    "        output = self.embedding(input).view(-1, 1, self.hidden_size)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        ### END SOLUTION\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "lsB5FHbr5qCo",
    "nbgrader": {
     "grade": false,
     "grade_id": "63a789",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH,teacher_forcing_ratio=0.5):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        if use_teacher_forcing: # Teacher forcing: Feed the target as the next decoder input\n",
    "            ### BEGIN SOLUTION\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            ### END SOLUTION\n",
    "        else:                   # Without teacher forcing: use its own predictions as the next input\n",
    "            ### BEGIN SOLUTION\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as decoder input\n",
    "            ### END SOLUTION\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        # Stop if terminate token (EOS) is generated\n",
    "        ### BEGIN SOLUTION\n",
    "        if decoder_input.item() == EOS_token: # Terminate token is returned. Stop\n",
    "            break\n",
    "        ### END SOLUTION\n",
    "\n",
    "    # Perform gradient step\n",
    "    ### BEGIN SOLUTION\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "_mKG9yHO5qCo",
    "nbgrader": {
     "grade": false,
     "grade_id": "e9d29b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "bcS-QHxa5qCo",
    "nbgrader": {
     "grade": false,
     "grade_id": "8d450b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "wTTnvOia5qCp",
    "nbgrader": {
     "grade": false,
     "grade_id": "fc1a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "J5XjaeOK5qCp",
    "nbgrader": {
     "grade": false,
     "grade_id": "ce4830",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "\n",
    "        decoded_words = []\n",
    "        # Translate the sentence. Substitute EOS_token with \"<EOS>\" and append to the end of decoded_words\n",
    "\n",
    "        ### BEGIN SOLUTION\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        ### END SOLUTION\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "oR-Arb035qCq",
    "nbgrader": {
     "grade": false,
     "grade_id": "361d6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "iYmwJSn05qCq",
    "nbgrader": {
     "grade": false,
     "grade_id": "2c20d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Loo-f1Z9NdFZ",
    "outputId": "a5c71bd8-f54e-481a-d17a-b6640771ccfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4345, 2803)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words, output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1Rl22miTWhY",
    "outputId": "f24bd132-a855-4824-e7d6-724675ea06d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['je suis un peu occupe .', 'i m a little busy .'],\n",
       " (tensor([[  6],\n",
       "          [ 11],\n",
       "          [ 66],\n",
       "          [635],\n",
       "          [ 30],\n",
       "          [  5],\n",
       "          [  1]], device='cuda:0'),\n",
       "  tensor([[  2],\n",
       "          [  3],\n",
       "          [ 42],\n",
       "          [884],\n",
       "          [ 19],\n",
       "          [  4],\n",
       "          [  1]], device='cuda:0')))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "training_pair = tensorsFromPair(pair)\n",
    "pair, training_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "YXQlIy3YWQJG",
    "outputId": "407a8402-3245-44bd-9b38-f8d1c1bbdd03"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'i m safe .'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[40][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsK8lc65U3zi",
    "outputId": "619640fb-4e8f-48d5-ce58-11507d088bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "je\n",
      "suis\n",
      "un\n",
      "peu\n",
      "occupe\n",
      ".\n",
      "EOS\n",
      "-----\n",
      "i\n",
      "m\n",
      "a\n",
      "little\n",
      "busy\n",
      ".\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "lang = [input_lang, output_lang]\n",
    "for j in range(2):\n",
    "  print (\"-----\")\n",
    "  for i in range(training_pair[j].size(0)):\n",
    "    print(lang[j].index2word[int(training_pair[j][i][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MloprVjqV6WU"
   },
   "outputs": [],
   "source": [
    "for i in range(training_pair[1].size(0)):\n",
    "  print(input_lang.index2word[int(training_pair[0][i][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "41T0MsyXT6hh"
   },
   "outputs": [],
   "source": [
    "input_tensor, output_tensor = training_pair[0], training_pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovTGmV_AUQxx",
    "outputId": "95049c23-22b1-4eed-826f-cd236d439360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length, target_length = input_tensor.size(0), output_tensor.size(0)\n",
    "input_length, target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "t1JUguj1Xn4e"
   },
   "outputs": [],
   "source": [
    "encoder_hidden = encoder.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIpS2IdWXprU",
    "outputId": "3340ce1f-6c71-4127-c348-2a5001ed487f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 256]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden, encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "h-gSXpijYHYo",
    "outputId": "7db7acd5-a5de-46a4-b159-98607dd18e10"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-5a297a53cf18>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_output' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "fG49WDOFXHFV"
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(input_tensor[0], encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VMq6_mLYNwO",
    "outputId": "49edd6c1-4323-4033-e8df-8bb5d55bc03e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 256]),\n",
       " tensor([[[-0.3660, -0.1374, -0.1627,  0.1791,  0.1956,  0.0855, -0.2766,\n",
       "            0.0155, -0.1747,  0.1660, -0.0397, -0.0998,  0.1683,  0.0571,\n",
       "            0.4571, -0.1024,  0.1151, -0.3474, -0.3121,  0.3060, -0.3228,\n",
       "            0.3123, -0.1322, -0.1340,  0.2122,  0.4841, -0.1493, -0.2204,\n",
       "            0.1846,  0.1844,  0.1363,  0.2888, -0.1850, -0.3460,  0.1411,\n",
       "            0.3320, -0.0729, -0.2061,  0.3027,  0.1849,  0.1027,  0.0321,\n",
       "            0.1789,  0.4468, -0.1360,  0.1420,  0.0072,  0.1781, -0.1733,\n",
       "           -0.2032, -0.1516,  0.2629, -0.0523, -0.2634,  0.1443, -0.0333,\n",
       "           -0.0531,  0.2466,  0.0352,  0.1251,  0.0216, -0.1368, -0.1189,\n",
       "            0.1208, -0.2075,  0.3448,  0.0245, -0.2518, -0.4847, -0.2586,\n",
       "           -0.4369,  0.0239,  0.2281,  0.1734, -0.0639, -0.1731, -0.1394,\n",
       "            0.1520, -0.0963,  0.1410, -0.0228, -0.1736,  0.1204, -0.1059,\n",
       "            0.1951,  0.2924, -0.2550,  0.1103, -0.0120, -0.1580, -0.0595,\n",
       "           -0.1540,  0.1275,  0.2796, -0.2650, -0.1939, -0.1275, -0.2090,\n",
       "            0.2865, -0.1984, -0.0071,  0.0740, -0.1652,  0.0388, -0.2436,\n",
       "           -0.0758,  0.0243, -0.3309, -0.4164, -0.1574, -0.0167,  0.1577,\n",
       "           -0.3180, -0.1795, -0.3337,  0.2104, -0.1122, -0.3425, -0.2013,\n",
       "           -0.0695,  0.0533,  0.0046,  0.1566, -0.1769,  0.1252, -0.0478,\n",
       "           -0.0792,  0.1460,  0.1207,  0.1678, -0.2813,  0.3881,  0.0119,\n",
       "            0.2842,  0.0794, -0.1721, -0.0216, -0.0061,  0.2143,  0.0639,\n",
       "           -0.3060,  0.0559,  0.4573,  0.1295, -0.2528,  0.1837,  0.2122,\n",
       "            0.2902, -0.1263,  0.3710,  0.0475, -0.1529, -0.2362,  0.0601,\n",
       "            0.1274,  0.2951, -0.2720,  0.3061, -0.2750,  0.2636, -0.0733,\n",
       "            0.4930,  0.2361,  0.2981,  0.1586, -0.3109, -0.0472,  0.0752,\n",
       "            0.0519, -0.1597, -0.5899, -0.4143,  0.0849, -0.3477,  0.3938,\n",
       "           -0.0685,  0.2412, -0.1122, -0.0816, -0.0071, -0.2104, -0.1078,\n",
       "           -0.1589, -0.1085, -0.1444,  0.0384, -0.0686,  0.2024,  0.3139,\n",
       "           -0.3099, -0.0605, -0.1266, -0.0333, -0.6069,  0.3407, -0.3170,\n",
       "           -0.0953,  0.2818, -0.0381,  0.4791,  0.0172, -0.0345,  0.1218,\n",
       "            0.1836,  0.2366,  0.5374,  0.1453, -0.1777, -0.2979, -0.2427,\n",
       "            0.3136, -0.1827,  0.2305, -0.0022,  0.0762,  0.0996, -0.1622,\n",
       "            0.0074,  0.1537,  0.1725, -0.3587, -0.1862, -0.1573, -0.0369,\n",
       "           -0.1891,  0.0670,  0.0043,  0.1711, -0.0716, -0.3730, -0.2763,\n",
       "           -0.3203, -0.2889,  0.1212,  0.2905, -0.1250, -0.2392,  0.3286,\n",
       "           -0.1759,  0.0162, -0.1118,  0.0303,  0.0854, -0.2726,  0.2338,\n",
       "            0.0559,  0.0402, -0.2629,  0.2949,  0.1159, -0.0440,  0.1869,\n",
       "            0.0744,  0.2326, -0.2423, -0.2515]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape, encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlT_rGwfYW8C",
    "outputId": "7fa4aa53-f059-4523-a1fb-712412a5cacf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3660, -0.1374, -0.1627,  0.1791,  0.1956,  0.0855, -0.2766,\n",
       "           0.0155, -0.1747,  0.1660, -0.0397, -0.0998,  0.1683,  0.0571,\n",
       "           0.4571, -0.1024,  0.1151, -0.3474, -0.3121,  0.3060, -0.3228,\n",
       "           0.3123, -0.1322, -0.1340,  0.2122,  0.4841, -0.1493, -0.2204,\n",
       "           0.1846,  0.1844,  0.1363,  0.2888, -0.1850, -0.3460,  0.1411,\n",
       "           0.3320, -0.0729, -0.2061,  0.3027,  0.1849,  0.1027,  0.0321,\n",
       "           0.1789,  0.4468, -0.1360,  0.1420,  0.0072,  0.1781, -0.1733,\n",
       "          -0.2032, -0.1516,  0.2629, -0.0523, -0.2634,  0.1443, -0.0333,\n",
       "          -0.0531,  0.2466,  0.0352,  0.1251,  0.0216, -0.1368, -0.1189,\n",
       "           0.1208, -0.2075,  0.3448,  0.0245, -0.2518, -0.4847, -0.2586,\n",
       "          -0.4369,  0.0239,  0.2281,  0.1734, -0.0639, -0.1731, -0.1394,\n",
       "           0.1520, -0.0963,  0.1410, -0.0228, -0.1736,  0.1204, -0.1059,\n",
       "           0.1951,  0.2924, -0.2550,  0.1103, -0.0120, -0.1580, -0.0595,\n",
       "          -0.1540,  0.1275,  0.2796, -0.2650, -0.1939, -0.1275, -0.2090,\n",
       "           0.2865, -0.1984, -0.0071,  0.0740, -0.1652,  0.0388, -0.2436,\n",
       "          -0.0758,  0.0243, -0.3309, -0.4164, -0.1574, -0.0167,  0.1577,\n",
       "          -0.3180, -0.1795, -0.3337,  0.2104, -0.1122, -0.3425, -0.2013,\n",
       "          -0.0695,  0.0533,  0.0046,  0.1566, -0.1769,  0.1252, -0.0478,\n",
       "          -0.0792,  0.1460,  0.1207,  0.1678, -0.2813,  0.3881,  0.0119,\n",
       "           0.2842,  0.0794, -0.1721, -0.0216, -0.0061,  0.2143,  0.0639,\n",
       "          -0.3060,  0.0559,  0.4573,  0.1295, -0.2528,  0.1837,  0.2122,\n",
       "           0.2902, -0.1263,  0.3710,  0.0475, -0.1529, -0.2362,  0.0601,\n",
       "           0.1274,  0.2951, -0.2720,  0.3061, -0.2750,  0.2636, -0.0733,\n",
       "           0.4930,  0.2361,  0.2981,  0.1586, -0.3109, -0.0472,  0.0752,\n",
       "           0.0519, -0.1597, -0.5899, -0.4143,  0.0849, -0.3477,  0.3938,\n",
       "          -0.0685,  0.2412, -0.1122, -0.0816, -0.0071, -0.2104, -0.1078,\n",
       "          -0.1589, -0.1085, -0.1444,  0.0384, -0.0686,  0.2024,  0.3139,\n",
       "          -0.3099, -0.0605, -0.1266, -0.0333, -0.6069,  0.3407, -0.3170,\n",
       "          -0.0953,  0.2818, -0.0381,  0.4791,  0.0172, -0.0345,  0.1218,\n",
       "           0.1836,  0.2366,  0.5374,  0.1453, -0.1777, -0.2979, -0.2427,\n",
       "           0.3136, -0.1827,  0.2305, -0.0022,  0.0762,  0.0996, -0.1622,\n",
       "           0.0074,  0.1537,  0.1725, -0.3587, -0.1862, -0.1573, -0.0369,\n",
       "          -0.1891,  0.0670,  0.0043,  0.1711, -0.0716, -0.3730, -0.2763,\n",
       "          -0.3203, -0.2889,  0.1212,  0.2905, -0.1250, -0.2392,  0.3286,\n",
       "          -0.1759,  0.0162, -0.1118,  0.0303,  0.0854, -0.2726,  0.2338,\n",
       "           0.0559,  0.0402, -0.2629,  0.2949,  0.1159, -0.0440,  0.1869,\n",
       "           0.0744,  0.2326, -0.2423, -0.2515]]], device='cuda:0',\n",
       "       grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "ODeWB3caYlSa"
   },
   "outputs": [],
   "source": [
    "for ei in range(1, input_length):\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlMZS-PgYosK",
    "outputId": "6f922fe1-32bb-4703-bfbe-88e97c38284b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5003,  0.0664,  0.0607, -0.0306,  0.3171, -0.1654, -0.0281,\n",
       "           -0.4843, -0.3115,  0.4210, -0.2452,  0.2667, -0.3991,  0.5182,\n",
       "            0.0693, -0.1961, -0.2001, -0.2919, -0.1187, -0.0310,  0.1213,\n",
       "           -0.0053, -0.4287,  0.1027, -0.1622, -0.1453,  0.1038, -0.3443,\n",
       "            0.0009,  0.1491, -0.1768, -0.6122, -0.4340, -0.4871, -0.1614,\n",
       "           -0.1898, -0.0332,  0.0071, -0.1185, -0.3717,  0.0487, -0.0689,\n",
       "            0.4097,  0.2257, -0.6109,  0.4033, -0.4832,  0.2019,  0.2767,\n",
       "           -0.2665, -0.1330,  0.1546, -0.1259, -0.3879, -0.1704,  0.1605,\n",
       "            0.2452,  0.1071,  0.0084,  0.0010, -0.1363,  0.5580, -0.1690,\n",
       "            0.3365,  0.3151, -0.2265, -0.1725, -0.2060,  0.4324,  0.1258,\n",
       "            0.0176,  0.2217,  0.2560, -0.1881,  0.1230, -0.1382,  0.0820,\n",
       "           -0.4468, -0.3240,  0.2064, -0.0768,  0.0479, -0.2700,  0.0912,\n",
       "            0.3942, -0.2609, -0.2430,  0.3965,  0.3604, -0.0798, -0.0924,\n",
       "            0.2362, -0.1323, -0.5466,  0.2357,  0.1105, -0.6781,  0.1718,\n",
       "           -0.1344, -0.2908,  0.1054, -0.3120,  0.2991, -0.2373,  0.2095,\n",
       "           -0.1212, -0.2455, -0.5178, -0.2387,  0.0897,  0.3359, -0.1288,\n",
       "            0.3066, -0.0361, -0.0592, -0.1113,  0.3364, -0.1833,  0.0828,\n",
       "           -0.1531,  0.0555, -0.4763, -0.4824,  0.1192, -0.1820,  0.2233,\n",
       "            0.0239, -0.0594,  0.2314, -0.2465,  0.2529,  0.3636, -0.1868,\n",
       "            0.1657, -0.4289, -0.3696,  0.4794,  0.2079, -0.2814, -0.4212,\n",
       "           -0.2911,  0.2297, -0.1246, -0.0924,  0.1074, -0.4105, -0.1664,\n",
       "            0.1735, -0.0257, -0.4918,  0.2381, -0.3199, -0.0330, -0.3988,\n",
       "            0.0935, -0.2074,  0.4242,  0.1938,  0.1046, -0.3797, -0.5357,\n",
       "            0.1866,  0.4428, -0.3181,  0.1550, -0.5269, -0.3849, -0.5268,\n",
       "           -0.1102,  0.1682, -0.3514, -0.2049, -0.2594, -0.1678, -0.1892,\n",
       "            0.3059,  0.2847,  0.2174,  0.4249, -0.0241, -0.2741,  0.1837,\n",
       "           -0.5140, -0.3468,  0.4082,  0.3710, -0.1709, -0.1704, -0.3129,\n",
       "           -0.4280,  0.6161,  0.1823, -0.1341,  0.4769,  0.1521, -0.0073,\n",
       "           -0.2218, -0.0563, -0.4323, -0.3167, -0.5476,  0.0216,  0.6186,\n",
       "            0.5619, -0.1501, -0.0629,  0.1753, -0.1989, -0.1424, -0.1728,\n",
       "           -0.3475, -0.3872,  0.3439, -0.1466,  0.3227,  0.2475, -0.2239,\n",
       "            0.0495, -0.1032,  0.2112, -0.1387,  0.2858, -0.0942,  0.3568,\n",
       "            0.3047,  0.0867,  0.0275,  0.0797, -0.2898,  0.3405,  0.5683,\n",
       "            0.2197,  0.1464, -0.3435, -0.4514, -0.0439, -0.2319,  0.1117,\n",
       "            0.7014,  0.2654, -0.0635, -0.3011, -0.5139,  0.2261, -0.2972,\n",
       "            0.5043,  0.1761, -0.0525,  0.4299, -0.0312, -0.4654,  0.1254,\n",
       "           -0.7209, -0.1465, -0.4640,  0.5665]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>),\n",
       " tensor([[[ 0.5003,  0.0664,  0.0607, -0.0306,  0.3171, -0.1654, -0.0281,\n",
       "           -0.4843, -0.3115,  0.4210, -0.2452,  0.2667, -0.3991,  0.5182,\n",
       "            0.0693, -0.1961, -0.2001, -0.2919, -0.1187, -0.0310,  0.1213,\n",
       "           -0.0053, -0.4287,  0.1027, -0.1622, -0.1453,  0.1038, -0.3443,\n",
       "            0.0009,  0.1491, -0.1768, -0.6122, -0.4340, -0.4871, -0.1614,\n",
       "           -0.1898, -0.0332,  0.0071, -0.1185, -0.3717,  0.0487, -0.0689,\n",
       "            0.4097,  0.2257, -0.6109,  0.4033, -0.4832,  0.2019,  0.2767,\n",
       "           -0.2665, -0.1330,  0.1546, -0.1259, -0.3879, -0.1704,  0.1605,\n",
       "            0.2452,  0.1071,  0.0084,  0.0010, -0.1363,  0.5580, -0.1690,\n",
       "            0.3365,  0.3151, -0.2265, -0.1725, -0.2060,  0.4324,  0.1258,\n",
       "            0.0176,  0.2217,  0.2560, -0.1881,  0.1230, -0.1382,  0.0820,\n",
       "           -0.4468, -0.3240,  0.2064, -0.0768,  0.0479, -0.2700,  0.0912,\n",
       "            0.3942, -0.2609, -0.2430,  0.3965,  0.3604, -0.0798, -0.0924,\n",
       "            0.2362, -0.1323, -0.5466,  0.2357,  0.1105, -0.6781,  0.1718,\n",
       "           -0.1344, -0.2908,  0.1054, -0.3120,  0.2991, -0.2373,  0.2095,\n",
       "           -0.1212, -0.2455, -0.5178, -0.2387,  0.0897,  0.3359, -0.1288,\n",
       "            0.3066, -0.0361, -0.0592, -0.1113,  0.3364, -0.1833,  0.0828,\n",
       "           -0.1531,  0.0555, -0.4763, -0.4824,  0.1192, -0.1820,  0.2233,\n",
       "            0.0239, -0.0594,  0.2314, -0.2465,  0.2529,  0.3636, -0.1868,\n",
       "            0.1657, -0.4289, -0.3696,  0.4794,  0.2079, -0.2814, -0.4212,\n",
       "           -0.2911,  0.2297, -0.1246, -0.0924,  0.1074, -0.4105, -0.1664,\n",
       "            0.1735, -0.0257, -0.4918,  0.2381, -0.3199, -0.0330, -0.3988,\n",
       "            0.0935, -0.2074,  0.4242,  0.1938,  0.1046, -0.3797, -0.5357,\n",
       "            0.1866,  0.4428, -0.3181,  0.1550, -0.5269, -0.3849, -0.5268,\n",
       "           -0.1102,  0.1682, -0.3514, -0.2049, -0.2594, -0.1678, -0.1892,\n",
       "            0.3059,  0.2847,  0.2174,  0.4249, -0.0241, -0.2741,  0.1837,\n",
       "           -0.5140, -0.3468,  0.4082,  0.3710, -0.1709, -0.1704, -0.3129,\n",
       "           -0.4280,  0.6161,  0.1823, -0.1341,  0.4769,  0.1521, -0.0073,\n",
       "           -0.2218, -0.0563, -0.4323, -0.3167, -0.5476,  0.0216,  0.6186,\n",
       "            0.5619, -0.1501, -0.0629,  0.1753, -0.1989, -0.1424, -0.1728,\n",
       "           -0.3475, -0.3872,  0.3439, -0.1466,  0.3227,  0.2475, -0.2239,\n",
       "            0.0495, -0.1032,  0.2112, -0.1387,  0.2858, -0.0942,  0.3568,\n",
       "            0.3047,  0.0867,  0.0275,  0.0797, -0.2898,  0.3405,  0.5683,\n",
       "            0.2197,  0.1464, -0.3435, -0.4514, -0.0439, -0.2319,  0.1117,\n",
       "            0.7014,  0.2654, -0.0635, -0.3011, -0.5139,  0.2261, -0.2972,\n",
       "            0.5043,  0.1761, -0.0525,  0.4299, -0.0312, -0.4654,  0.1254,\n",
       "           -0.7209, -0.1465, -0.4640,  0.5665]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output, encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "0UxfQ3wFZjuz"
   },
   "outputs": [],
   "source": [
    "decoder_input = torch.tensor([[SOS_token]], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8X-KVlKgZmhj",
    "outputId": "bd807176-f931-4821-b1a7-9ceb2feb44ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "QL102xOFZ3oc"
   },
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_hidden\n",
    "decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CcW-vQRaEaw",
    "outputId": "46e18909-4015-4575-fa82-34d482a87d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx69roGnauX0"
   },
   "outputs": [],
   "source": [
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "            decoder_input, decoder_hidden)\n",
    "        if use_teacher_forcing: # Teacher forcing: Feed the target as the next decoder input\n",
    "            ### BEGIN SOLUTION\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            ### END SOLUTION\n",
    "        else:                   # Without teacher forcing: use its own predictions as the next input\n",
    "            ### BEGIN SOLUTION\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as decoder input\n",
    "            ### END SOLUTION\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        # Stop if terminate token (EOS) is generated\n",
    "        ### BEGIN SOLUTION\n",
    "        if decoder_input.item() == EOS_token: # Terminate token is returned. Stop\n",
    "            break\n",
    "        ### END SOLUTION\n",
    "\n",
    "    # Perform gradient step\n",
    "    ### BEGIN SOLUTION\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8vx2VOoaxK1",
    "outputId": "273c9088-ab1f-46bf-ab38-c79f4fbc400b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_teacher_forcing = True if random.random() < 0.5 else False\n",
    "use_teacher_forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpDEw3c5a-Ji",
    "outputId": "d4c91ca6-3487-4f5e-974e-a6098dea2f5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoder_output not defined yet\n",
    "#decoder_hidden (era l'output dell'encoder)\n",
    "#decoder_input # tensor([[0]], device='cuda:0')\n",
    "decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZpktkxsbU1R",
    "outputId": "21959456-da32-47ae-d7f2-96d3de6cb2bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-8.0365, -8.0645, -7.8952,  ..., -7.9550, -8.0629, -8.0634]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[[ 0.2803, -0.1187,  0.1272, -0.1398,  0.3039,  0.1148, -0.1754,\n",
       "           -0.2082,  0.1313,  0.0236, -0.3504, -0.0618, -0.2385,  0.1751,\n",
       "            0.2292,  0.0911,  0.0673, -0.1782, -0.0619, -0.1751,  0.1129,\n",
       "            0.3809, -0.4244,  0.1414, -0.1107, -0.1238, -0.0176, -0.3950,\n",
       "            0.1365,  0.2115, -0.0188, -0.2534, -0.1923,  0.1726,  0.3072,\n",
       "           -0.0378, -0.2927, -0.0770, -0.2897, -0.1238,  0.2608, -0.4358,\n",
       "            0.2715, -0.0042,  0.1687,  0.2844, -0.1135, -0.0777,  0.2595,\n",
       "            0.0401, -0.1007,  0.1959, -0.1336,  0.0626,  0.0834, -0.0325,\n",
       "            0.1240, -0.1252, -0.0791,  0.1350,  0.2160,  0.3585, -0.0300,\n",
       "            0.2731, -0.0146, -0.2522,  0.1297, -0.0670,  0.1792,  0.1342,\n",
       "            0.1316,  0.0170,  0.1274, -0.3153, -0.2306,  0.1310,  0.1500,\n",
       "           -0.5460, -0.2305, -0.0824, -0.0102, -0.2978,  0.1962, -0.0085,\n",
       "           -0.1882, -0.2192,  0.2513,  0.3688, -0.0066,  0.0630,  0.0780,\n",
       "            0.4068, -0.0454, -0.3343,  0.2313, -0.2787, -0.4640,  0.2215,\n",
       "           -0.0465, -0.0196,  0.4683, -0.0677,  0.0896, -0.2039,  0.0784,\n",
       "           -0.0996, -0.3574, -0.4079, -0.3825,  0.1070,  0.2821, -0.0904,\n",
       "            0.0137, -0.2214,  0.0297,  0.2056,  0.1462,  0.1941,  0.0030,\n",
       "           -0.2026, -0.2529,  0.1142, -0.0683,  0.0008,  0.0998,  0.1674,\n",
       "           -0.0224,  0.1466,  0.0749, -0.2564, -0.0185,  0.1744, -0.1125,\n",
       "            0.2391, -0.3957,  0.1023,  0.2349,  0.3742, -0.1765, -0.0589,\n",
       "           -0.0903,  0.2759,  0.3221,  0.2369,  0.2726,  0.0770, -0.0516,\n",
       "            0.1425,  0.0214, -0.5240,  0.3757, -0.2415,  0.2025, -0.3994,\n",
       "           -0.2722,  0.2469,  0.3636,  0.2686, -0.0916, -0.2173,  0.0510,\n",
       "            0.1286, -0.0492, -0.1453,  0.0193, -0.2982, -0.1402, -0.2587,\n",
       "           -0.0387,  0.1369, -0.1867, -0.4568, -0.1413, -0.1939, -0.0629,\n",
       "            0.3442,  0.2996,  0.2623,  0.2246, -0.1536, -0.2756,  0.3407,\n",
       "           -0.4950, -0.1378,  0.4757,  0.5335, -0.1872, -0.1480, -0.4666,\n",
       "           -0.3545,  0.1992,  0.3002,  0.0610,  0.5768, -0.0045, -0.4501,\n",
       "           -0.1951, -0.0350, -0.2403, -0.1127,  0.1402,  0.2663,  0.3243,\n",
       "            0.2931,  0.1665, -0.2477, -0.3266, -0.0034, -0.1504, -0.2289,\n",
       "           -0.0521, -0.1653,  0.2077,  0.1168,  0.1353, -0.0985,  0.0770,\n",
       "           -0.0706, -0.0701, -0.0676, -0.1787,  0.3686,  0.1098,  0.1617,\n",
       "            0.0639,  0.0247, -0.1304,  0.1098,  0.0067,  0.2768,  0.3177,\n",
       "            0.2014, -0.0893, -0.2784, -0.4402, -0.1737, -0.2803,  0.3585,\n",
       "           -0.0161,  0.2929, -0.3347, -0.5381, -0.1585,  0.2015,  0.1545,\n",
       "            0.0987,  0.0209, -0.1412,  0.0388, -0.0972, -0.1579,  0.1834,\n",
       "           -0.4026,  0.0076, -0.4698,  0.5342]]], device='cuda:0',\n",
       "        grad_fn=<CudnnRnnBackward0>))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output, decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Vd-1h6rbey7",
    "outputId": "2041f501-6d9d-4f68-f83e-492724ff59d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2803]), torch.Size([1, 1, 256]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape, decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CfGLtI9bxGq",
    "outputId": "7e39c979-a548-40c6-ee10-f9a31542c667"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2], device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor = output_tensor\n",
    "target_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKZNk84UcTcj",
    "outputId": "a5ab7fdd-0ea6-477e-85ba-058db94cb118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.8952, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "criterion(decoder_output, target_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVqmMMtbckhU",
    "outputId": "29e1e1d0-cf10-4fee-f3cb-3ebec46c492a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-8.0365, -8.0645, -7.8952,  ..., -7.9550, -8.0629, -8.0634]],\n",
       "        device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([2], device='cuda:0'))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output, target_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDFcEJ1Fc078",
    "outputId": "deb06e32-6180-49da-f208-6ccde7a72734"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOb4yX-vQVqJ",
    "outputId": "6bd0eede-e223-46f7-ec9e-ff7671997ec5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(4345, 256), GRU(256, 256))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embedding, encoder.gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uot5Uw8aNXOs",
    "outputId": "b1950989-b9f8-44b6-efb5-d95ad4f57d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 6s (- 15m 28s) (5000 6%) 2.9076\n",
      "2m 7s (- 13m 48s) (10000 13%) 2.3489\n",
      "3m 8s (- 12m 32s) (15000 20%) 2.0182\n",
      "4m 8s (- 11m 24s) (20000 26%) 1.7885\n",
      "5m 11s (- 10m 22s) (25000 33%) 1.5558\n",
      "6m 11s (- 9m 17s) (30000 40%) 1.3790\n",
      "7m 12s (- 8m 14s) (35000 46%) 1.2102\n",
      "8m 12s (- 7m 11s) (40000 53%) 1.0689\n",
      "9m 12s (- 6m 8s) (45000 60%) 0.9581\n",
      "10m 14s (- 5m 7s) (50000 66%) 0.8400\n",
      "11m 14s (- 4m 5s) (55000 73%) 0.7675\n",
      "12m 14s (- 3m 3s) (60000 80%) 0.6827\n",
      "13m 13s (- 2m 2s) (65000 86%) 0.6066\n",
      "14m 13s (- 1m 0s) (70000 93%) 0.5455\n",
      "15m 13s (- 0m 0s) (75000 100%) 0.4780\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder, decoder, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8F2jguS5qCq",
    "nbgrader": {
     "grade": false,
     "grade_id": "047580",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "5a36b9b3-a25a-4276-9ea1-e41ca02b9239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> il sait nager comme un poisson .\n",
      "= he is able to swim like a fish .\n",
      "< he is able to swim a fish . <EOS>\n",
      "\n",
      "> ce sont des employees a temps partiel .\n",
      "= they re part time employees .\n",
      "< they re part time time . <EOS>\n",
      "\n",
      "> c est un mordu de cinema .\n",
      "= he s a movie buff .\n",
      "< he s a movie . <EOS>\n",
      "\n",
      "> je peux nager dans la riviere .\n",
      "= i am allowed to swim in the river .\n",
      "< i am allowed to swim in the river . <EOS>\n",
      "\n",
      "> ils ne vont pas revenir .\n",
      "= they re not coming back .\n",
      "< they re not coming back . <EOS>\n",
      "\n",
      "> c est mon patron .\n",
      "= he is my boss .\n",
      "< he is my boss . <EOS>\n",
      "\n",
      "> il est allergique aux chats .\n",
      "= he s allergic to cats .\n",
      "< he s allergic to cats . <EOS>\n",
      "\n",
      "> je suis tres occupee tom .\n",
      "= i m really busy tom .\n",
      "< i m very busy tom . <EOS>\n",
      "\n",
      "> vous etes suffisante .\n",
      "= you re conceited .\n",
      "< you re conceited . <EOS>\n",
      "\n",
      "> je suis assez en colere .\n",
      "= i m pretty angry .\n",
      "< i m very angry . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwTjU07KhszD",
    "outputId": "849bff39-b7b8-406e-e0a0-cbe305e0c0df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'very', 'hungry', '.', '<EOS>']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, \"je ai tres faim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uc4bi_dxiAJo",
    "outputId": "cccaebd4-5acd-481f-a825-86bdf04124f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'having', 'the', 'same', 'of', '.', '.', '<EOS>']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, \"maintenant je dois preparer le dejeuner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxkd7-pXiO89",
    "outputId": "57e36846-6e5b-4127-cc52-98fe1798c525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'very', 'good', '.', '<EOS>']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder, decoder, \"je suis tres bon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "Kd4ROHGQh515"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb8MrvcnieZy",
    "outputId": "d021223c-34c0-4df0-fdd5-ac5925de74bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.word2count[\"lunch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "Ad2qRJAU5qCr",
    "nbgrader": {
     "grade": true,
     "grade_id": "bb686a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "5b688380-9ec5-4a6a-da3b-805e6c0fe013"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-7bc6f5beb84b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'<EOS>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m### END HIDDEN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "res = []\n",
    "for pair in pairs[:40]:\n",
    "    output_words = evaluate(encoder, decoder, pair[0])\n",
    "    res.append(output_words == pair[1].split(' ') + ['<EOS>'])\n",
    "assert np.mean(res) > 0.55\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6N2KmDwm9Sv8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
